{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65cb1f38",
   "metadata": {},
   "source": [
    "# **üìä FBref Multi-League Multi-Season Scraper**  \n",
    "**Using Selenium (Firefox + GeckoDriverManager)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7d3d7d",
   "metadata": {},
   "source": [
    "----\n",
    "### **üì¶üìåüõ†Ô∏è Python & Selenium Imports Overview**\n",
    "---\n",
    "| Import | Purpose / Use |\n",
    "|--------|---------------|\n",
    "| `from selenium import webdriver` | Provides the main interface to control web browsers via Selenium. Used to open, navigate, and interact with webpages. |\n",
    "| `from selenium.webdriver.firefox.service import Service` | Used to specify the Firefox driver executable (GeckoDriver) service when initializing the Firefox WebDriver. |\n",
    "| `from selenium.webdriver.firefox.options import Options` | Allows configuring Firefox browser options such as window size, headless mode, and other preferences. |\n",
    "| `from selenium.webdriver.common.by import By` | Provides methods to locate elements on a webpage (e.g., `By.ID`, `By.CLASS_NAME`, `By.XPATH`). |\n",
    "| `from webdriver_manager.firefox import GeckoDriverManager` | Automatically downloads and manages the correct version of GeckoDriver (Firefox WebDriver) for your system. |\n",
    "| `from io import StringIO` | Allows treating a string as a file-like object. Used here to read HTML tables into pandas DataFrames using `pd.read_html()`. |\n",
    "| `import pandas as pd` | The main data manipulation library in Python. Used for creating, cleaning, and merging DataFrames. |\n",
    "| `import time` | Provides sleep and time functions, used here to add delays between requests for safer web scraping. |\n",
    "| `import random` | Provides random number functions, used here to vary sleep times and mimic human-like browsing behavior. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c9f2314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- IMPORTS ---------------- #\n",
    "\n",
    "# Selenium imports ‚Üí used for automating browser actions\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Automatically installs the correct GeckoDriver (Firefox driver)\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "\n",
    "# Other Python imports\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc651fe",
   "metadata": {},
   "source": [
    "### **üìò 1) Understanding FBref Website Structure for Data Scraping**\n",
    "\n",
    "**FBref.com** is one of the most detailed and reliable sources for football statistics.  \n",
    "It provides rich data across multiple leagues, seasons, teams, and individual players.\n",
    "\n",
    "This section explains **how FBref URLs work**, how **league IDs** are assigned, and how **HTML tables** are structured, so you can scrape them correctly.\n",
    "\n",
    "---\n",
    "\n",
    "##### **üèÜ What FBref Provides**\n",
    "\n",
    "FBref contains an enormous collection of football data:\n",
    "\n",
    "- League & team standings  \n",
    "- Player match logs  \n",
    "- Detailed shooting, passing, possession, and defensive metrics  \n",
    "- Goalkeeping analytics  \n",
    "- Advanced xG/xAG metrics  \n",
    "- Progressive passing and carrying stats  \n",
    "\n",
    "---\n",
    "\n",
    "##### **üî¢ FBref League IDs (Competition IDs)**\n",
    "\n",
    "Each league on FBref has a unique **competition ID**, used inside the URLs.\n",
    "\n",
    "| League | Competition ID |\n",
    "|--------|-----------------|\n",
    "| Premier League **(England)** | `9` |\n",
    "| La Liga **(Spain)** | `12` |\n",
    "| Serie A **(Italy)** | `11` |\n",
    "| Bundesliga **(Germany)** | `20` |\n",
    "| Ligue 1 **(France)** | `13` |\n",
    "| Primeira Liga **(Portugal)** | `32` |\n",
    "| Eredivisie **(Netherlands)** | `23` |\n",
    "\n",
    "---\n",
    "\n",
    "##### **üåê FBref URL Structure**\n",
    "\n",
    "All FBref league pages follow this structure:\n",
    "\n",
    "`https://fbref.com/en/comps/<LEAGUE_ID>/<YEAR_CODE>/<CATEGORY>/<SEASON-LEAGUE-NAME>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da6aa7f",
   "metadata": {},
   "source": [
    "---\n",
    "### **üñ•Ô∏è 2) Selenium Browser Setup**  \n",
    "Using **Firefox** + **GeckoDriverManager** (auto-install)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4feb548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "#  1. Configure Firefox Browser Options\n",
    "# ------------------------------------------------------------\n",
    "options = Options()\n",
    "\n",
    "# Set browser window width (useful for consistent rendering)\n",
    "options.add_argument(\"--width=1280\")\n",
    "\n",
    "# Set browser height (ensures full table visibility)\n",
    "options.add_argument(\"--height=800\")\n",
    "\n",
    "# Optional: Run browser in headless mode (no visible UI)\n",
    "# This is useful for servers / background scraping\n",
    "# options.add_argument(\"--headless\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "#  2. Create Firefox WebDriver using GeckoDriver\n",
    "# ------------------------------------------------------------\n",
    "driver = webdriver.Firefox(\n",
    "    service=Service(GeckoDriverManager().install()),  # Auto-installs correct driver version\n",
    "    options=options                                   # Apply browser settings above\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f093f2f0",
   "metadata": {},
   "source": [
    "---\n",
    "### **üåç 3) Set Leagues and Seasons**  \n",
    "- **Competition IDs** + **Season Folders**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "543837b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1. Set the League IDs used in URL\n",
    "# ------------------------------------------------------------\n",
    "leagues = {\n",
    "    \"Primeira Liga\": 32,\n",
    "    \"La Liga\": 12,\n",
    "    \"Serie A\": 11,\n",
    "    \"Bundesliga\": 20,\n",
    "    \"Ligue 1\": 13,\n",
    "    \"Premier League\": 9,\n",
    "    \"Eredivisie\": 23\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Set the Season Format used in URL\n",
    "# ------------------------------------------------------------\n",
    "seasons = {\n",
    "    \"2018-2019\": 2019,\n",
    "    \"2019-2020\": 2020,\n",
    "    \"2020-2021\": 2021,\n",
    "    \"2021-2022\": 2022,\n",
    "    \"2022-2023\": 2023,\n",
    "    \"2023-2024\": 2024\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 3. Store the entire data via League and Season wise combination \n",
    "# ------------------------------------------------------------------------\n",
    "all_data = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d1eac-f4e3-4a92-8ed0-13957da46cd1",
   "metadata": {},
   "source": [
    "---\n",
    "### **üìì 4) Function that scrapes tabular data from the Website**  \n",
    "- Based on **URL**, **table_id** + **season** + **league_name**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad95e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fbref_table(url, table_id, season, league_name, max_retries=3):\n",
    "    \"\"\" Opens an FBref page using Selenium, extracts a specific stats table, cleans it, \n",
    "    and returns a Pandas DataFrame. \n",
    "    PARAMETERS: \n",
    "    url (str) -> full URL of the page to scrape \n",
    "    table_id (str) -> HTML table ID (ex: 'stats_standard') \n",
    "    season (str) -> season like '2023-2024' \n",
    "    league_name (str)-> league name like 'Premier League'\n",
    "\n",
    "    Opens an FBref page using Selenium, extracts table with retry logic.\n",
    "    \"\"\"\n",
    "\n",
    "    attempt = 1\n",
    "    # ------------------------------------------------------------\n",
    "    # Scraping loop that automatically retries whenever a table fails due to:\n",
    "    # 1) Timeouts\n",
    "    # 2) Slow Selenium load\n",
    "    # 3) Temporary FBref blocking\n",
    "    # 4) Partial page loads\n",
    "    # It retries up to 3 times before skipping the table.\n",
    "    # ------------------------------------------------------------\n",
    "    while attempt <= max_retries:\n",
    "        try:\n",
    "            # ------------------------------------------------------------\n",
    "            # 1. Load the webpage using Selenium\n",
    "            # ------------------------------------------------------------\n",
    "            driver.get(url)\n",
    "\n",
    "            # Random wait to mimic human browsing & avoid FBref blocking\n",
    "            time.sleep(random.uniform(4, 7))\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # 2. Locate the table using its HTML ID\n",
    "            # ------------------------------------------------------------\n",
    "            table = driver.find_element(By.ID, table_id)\n",
    "\n",
    "            html = table.get_attribute(\"outerHTML\")\n",
    "\n",
    "            df = pd.read_html(StringIO(html))[0]\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # 4. Fix MultiIndex headers\n",
    "            # ------------------------------------------------------------\n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                df.columns = ['_'.join(col).strip() for col in df.columns.values]\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # 5. Clean column names\n",
    "            # ------------------------------------------------------------\n",
    "            df.columns = (\n",
    "                df.columns\n",
    "                .str.replace(\"Unnamed: \\\\d+_level_0_\", \"\", regex=True)\n",
    "                .str.replace(\"Standard Stats_\", \"\")\n",
    "                .str.replace(\"Shooting_\", \"\")\n",
    "                .str.replace(\"Passing_\", \"\")\n",
    "                .str.replace(\"GCA_\", \"\")\n",
    "                .str.replace(\" \", \"_\")\n",
    "                .str.replace(\"-\", \"_\")\n",
    "                .str.strip(\"_\")\n",
    "            )\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # 6. Normalize Player column\n",
    "            # ------------------------------------------------------------\n",
    "            player_col = [c for c in df.columns if \"Player\" in c or \"player\" in c][0]\n",
    "            df.rename(columns={player_col: \"Player\"}, inplace=True)\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # 7. Drop repeated header rows\n",
    "            # ------------------------------------------------------------\n",
    "            df = df[df[\"Player\"].notna()]\n",
    "            df = df[df[\"Player\"].str.lower() != \"player\"]\n",
    "            df = df[df[\"Player\"].str.lower() != \"matches\"]\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # 8. Add metadata\n",
    "            # ------------------------------------------------------------\n",
    "            df[\"Season\"] = seasons[season]\n",
    "            df[\"League\"] = league_name\n",
    "\n",
    "            return df\n",
    "\n",
    "        except Exception as e:\n",
    "            wait_time = [3, 6, 10][attempt - 1]\n",
    "\n",
    "            print(f\"‚ö†Ô∏è Error on attempt {attempt}/{max_retries} scraping {league_name} {season}\")\n",
    "            print(f\"   Error: {str(e)}\")\n",
    "            print(f\"‚è≥ Retrying in {wait_time} seconds...\\n\")\n",
    "\n",
    "            time.sleep(wait_time)\n",
    "            attempt += 1\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # ‚ùå After all retries failed ‚Äî return empty df\n",
    "    # ------------------------------------------------------------\n",
    "    print(f\"‚ùå Failed to scrape {league_name} {season} after {max_retries} attempts.\")\n",
    "    return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95da5fe",
   "metadata": {},
   "source": [
    "---\n",
    "### **üîÅ 5) Main Scraping Loop**\n",
    "- Scrapes **Standard** + **Shooting** + **Passing** Tables  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b54062e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öΩ Scraping Primeira Liga ‚Äî 2018-2019\n",
      "‚úÖ Finished Primeira Liga 2018-2019: 540 players\n",
      "\n",
      "‚öΩ Scraping Primeira Liga ‚Äî 2019-2020\n",
      "‚úÖ Finished Primeira Liga 2019-2020: 562 players\n",
      "\n",
      "‚öΩ Scraping Primeira Liga ‚Äî 2020-2021\n",
      "‚úÖ Finished Primeira Liga 2020-2021: 543 players\n",
      "\n",
      "‚öΩ Scraping Primeira Liga ‚Äî 2021-2022\n",
      "‚úÖ Finished Primeira Liga 2021-2022: 581 players\n",
      "\n",
      "‚öΩ Scraping Primeira Liga ‚Äî 2022-2023\n",
      "‚úÖ Finished Primeira Liga 2022-2023: 580 players\n",
      "\n",
      "‚öΩ Scraping Primeira Liga ‚Äî 2023-2024\n",
      "‚úÖ Finished Primeira Liga 2023-2024: 536 players\n",
      "\n",
      "‚öΩ Scraping La Liga ‚Äî 2018-2019\n",
      "‚úÖ Finished La Liga 2018-2019: 544 players\n",
      "\n",
      "‚öΩ Scraping La Liga ‚Äî 2019-2020\n",
      "‚úÖ Finished La Liga 2019-2020: 570 players\n",
      "\n",
      "‚öΩ Scraping La Liga ‚Äî 2020-2021\n",
      "‚úÖ Finished La Liga 2020-2021: 582 players\n",
      "\n",
      "‚öΩ Scraping La Liga ‚Äî 2021-2022\n",
      "‚úÖ Finished La Liga 2021-2022: 617 players\n",
      "\n",
      "‚öΩ Scraping La Liga ‚Äî 2022-2023\n",
      "‚úÖ Finished La Liga 2022-2023: 596 players\n",
      "\n",
      "‚öΩ Scraping La Liga ‚Äî 2023-2024\n",
      "‚úÖ Finished La Liga 2023-2024: 609 players\n",
      "\n",
      "‚öΩ Scraping Serie A ‚Äî 2018-2019\n",
      "‚úÖ Finished Serie A 2018-2019: 569 players\n",
      "\n",
      "‚öΩ Scraping Serie A ‚Äî 2019-2020\n",
      "‚úÖ Finished Serie A 2019-2020: 600 players\n",
      "\n",
      "‚öΩ Scraping Serie A ‚Äî 2020-2021\n",
      "‚úÖ Finished Serie A 2020-2021: 619 players\n",
      "\n",
      "‚öΩ Scraping Serie A ‚Äî 2021-2022\n",
      "‚úÖ Finished Serie A 2021-2022: 632 players\n",
      "\n",
      "‚öΩ Scraping Serie A ‚Äî 2022-2023\n",
      "‚úÖ Finished Serie A 2022-2023: 603 players\n",
      "\n",
      "‚öΩ Scraping Serie A ‚Äî 2023-2024\n",
      "‚úÖ Finished Serie A 2023-2024: 616 players\n",
      "\n",
      "‚öΩ Scraping Bundesliga ‚Äî 2018-2019\n",
      "‚úÖ Finished Bundesliga 2018-2019: 474 players\n",
      "\n",
      "‚öΩ Scraping Bundesliga ‚Äî 2019-2020\n",
      "‚úÖ Finished Bundesliga 2019-2020: 498 players\n",
      "\n",
      "‚öΩ Scraping Bundesliga ‚Äî 2020-2021\n",
      "‚úÖ Finished Bundesliga 2020-2021: 505 players\n",
      "\n",
      "‚öΩ Scraping Bundesliga ‚Äî 2021-2022\n",
      "‚úÖ Finished Bundesliga 2021-2022: 523 players\n",
      "\n",
      "‚öΩ Scraping Bundesliga ‚Äî 2022-2023\n",
      "‚úÖ Finished Bundesliga 2022-2023: 515 players\n",
      "\n",
      "‚öΩ Scraping Bundesliga ‚Äî 2023-2024\n",
      "‚úÖ Finished Bundesliga 2023-2024: 507 players\n",
      "\n",
      "‚öΩ Scraping Ligue 1 ‚Äî 2018-2019\n",
      "‚úÖ Finished Ligue 1 2018-2019: 561 players\n",
      "\n",
      "‚öΩ Scraping Ligue 1 ‚Äî 2019-2020\n",
      "‚úÖ Finished Ligue 1 2019-2020: 542 players\n",
      "\n",
      "‚öΩ Scraping Ligue 1 ‚Äî 2020-2021\n",
      "‚úÖ Finished Ligue 1 2020-2021: 584 players\n",
      "\n",
      "‚öΩ Scraping Ligue 1 ‚Äî 2021-2022\n",
      "‚úÖ Finished Ligue 1 2021-2022: 604 players\n",
      "\n",
      "‚öΩ Scraping Ligue 1 ‚Äî 2022-2023\n",
      "‚úÖ Finished Ligue 1 2022-2023: 606 players\n",
      "\n",
      "‚öΩ Scraping Ligue 1 ‚Äî 2023-2024\n",
      "‚úÖ Finished Ligue 1 2023-2024: 540 players\n",
      "\n",
      "‚öΩ Scraping Premier League ‚Äî 2018-2019\n",
      "‚úÖ Finished Premier League 2018-2019: 508 players\n",
      "\n",
      "‚öΩ Scraping Premier League ‚Äî 2019-2020\n",
      "‚úÖ Finished Premier League 2019-2020: 522 players\n",
      "\n",
      "‚öΩ Scraping Premier League ‚Äî 2020-2021\n",
      "‚úÖ Finished Premier League 2020-2021: 532 players\n",
      "\n",
      "‚öΩ Scraping Premier League ‚Äî 2021-2022\n",
      "‚úÖ Finished Premier League 2021-2022: 546 players\n",
      "\n",
      "‚öΩ Scraping Premier League ‚Äî 2022-2023\n",
      "‚úÖ Finished Premier League 2022-2023: 569 players\n",
      "\n",
      "‚öΩ Scraping Premier League ‚Äî 2023-2024\n",
      "‚úÖ Finished Premier League 2023-2024: 580 players\n",
      "\n",
      "‚öΩ Scraping Eredivisie ‚Äî 2018-2019\n",
      "‚úÖ Finished Eredivisie 2018-2019: 479 players\n",
      "\n",
      "‚öΩ Scraping Eredivisie ‚Äî 2019-2020\n",
      "‚úÖ Finished Eredivisie 2019-2020: 484 players\n",
      "\n",
      "‚öΩ Scraping Eredivisie ‚Äî 2020-2021\n",
      "‚úÖ Finished Eredivisie 2020-2021: 522 players\n",
      "\n",
      "‚öΩ Scraping Eredivisie ‚Äî 2021-2022\n",
      "‚úÖ Finished Eredivisie 2021-2022: 533 players\n",
      "\n",
      "‚öΩ Scraping Eredivisie ‚Äî 2022-2023\n",
      "‚úÖ Finished Eredivisie 2022-2023: 526 players\n",
      "\n",
      "‚öΩ Scraping Eredivisie ‚Äî 2023-2024\n",
      "‚úÖ Finished Eredivisie 2023-2024: 524 players\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# üîÅ LOOP OVER ALL LEAGUES & SEASONS\n",
    "# ------------------------------------------------------------\n",
    "for league_name, league_code in leagues.items():\n",
    "    for season in seasons.keys():\n",
    "\n",
    "        print(f\"\\n‚öΩ Scraping {league_name} ‚Äî {season}\")\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        #  1. Build FBref slug used in every stats URL\n",
    "        # ------------------------------------------------------------\n",
    "        # Example: \"2023-Premier-League-Stats\"\n",
    "        slug = f\"{season}-{league_name.replace(' ', '-')}-Stats\"\n",
    "\n",
    "        # Base URL portion for the league + season\n",
    "        base_url = f\"https://fbref.com/en/comps/{league_code}/{season}\"\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        #  2. Dictionary of stats pages to scrape\n",
    "        # This allows dynamic URL generation\n",
    "        # ------------------------------------------------------------\n",
    "        stat_types = {\n",
    "            \"standard\": \"stats\",\n",
    "            \"shooting\": \"shooting\",\n",
    "            \"passing\":  \"passing\",\n",
    "            \"gca\":      \"gca\"\n",
    "        }\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        #  3. Dynamically create final URLs for each stats table\n",
    "        # ------------------------------------------------------------\n",
    "        urls = {\n",
    "            stat_name: f\"{base_url}/{path}/{slug}\"\n",
    "            for stat_name, path in stat_types.items()\n",
    "        }\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        #  4. Download all FBref tables\n",
    "        # get_fbref_table() is your parsing function\n",
    "        # ------------------------------------------------------------\n",
    "        df_std  = get_fbref_table(urls[\"standard\"], \"stats_standard\", season, league_name)\n",
    "        df_shot = get_fbref_table(urls[\"shooting\"], \"stats_shooting\", season, league_name)\n",
    "        df_pass = get_fbref_table(urls[\"passing\"],  \"stats_passing\",  season, league_name)\n",
    "        df_gca  = get_fbref_table(urls[\"gca\"],      \"stats_gca\",      season, league_name)\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        #  5. Skip season if all tables are empty\n",
    "        # ------------------------------------------------------------\n",
    "        if df_std.empty and df_shot.empty and df_pass.empty and df_gca.empty:\n",
    "            print(f\"‚ö†Ô∏è No data for {league_name} {season}\")\n",
    "            continue\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        #  6. Begin merging with STANDARD table as the base\n",
    "        # ------------------------------------------------------------\n",
    "        merged = df_std\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        #  7. Merge Shooting table \n",
    "        # ------------------------------------------------------------\n",
    "        if not df_shot.empty:\n",
    "            merged = merged.merge(\n",
    "                df_shot,\n",
    "                left_on=[\"Season\", \"League\", \"Rk\"],      # keys in standard table\n",
    "                right_on=[\"Season\", \"League\", \"Rk\"],     # keys in shooting table\n",
    "                how=\"inner\",\n",
    "                suffixes=(\"\", \"_shot\")                   # suffix for shooting stats\n",
    "            )\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        #  8. Merge Passing table \n",
    "        # ------------------------------------------------------------\n",
    "        if not df_pass.empty:\n",
    "            merged = merged.merge(\n",
    "                df_pass,\n",
    "                left_on=[\"Season\", \"League\", \"Rk\"],\n",
    "                right_on=[\"Season\", \"League\", \"Rk\"],\n",
    "                how=\"inner\",\n",
    "                suffixes=(\"\", \"_pass\")\n",
    "            )\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        #  9. Merge GCA table \n",
    "        # ------------------------------------------------------------\n",
    "        if not df_gca.empty:\n",
    "            merged = merged.merge(\n",
    "                df_gca,\n",
    "                left_on=[\"Season\", \"League\", \"Rk\"],\n",
    "                right_on=[\"Season\", \"League\", \"Rk\"],\n",
    "                how=\"inner\",\n",
    "                suffixes=(\"\", \"_gca\")\n",
    "            )\n",
    "\n",
    "       \n",
    "        # ------------------------------------------------------------\n",
    "        #  10. Store merged dataset for this league & season\n",
    "        # ------------------------------------------------------------\n",
    "        merged[\"League\"] = league_name\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        #  11. Store merged dataset for this league & season\n",
    "        # ------------------------------------------------------------\n",
    "        all_data.append(merged)\n",
    "        print(f\"‚úÖ Finished {league_name} {season}: {len(merged)} players\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ba99e1",
   "metadata": {},
   "source": [
    "---\n",
    "### **üíæ 6) Save Final CSV**\n",
    "- Merged across all leagues and seasons.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce69c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Saved successfully!\n",
      "Shape: (23283, 119)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "#  1. Check if we have any scraped data\n",
    "# ------------------------------------------------------------\n",
    "if all_data:\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    #  2. Merge all league-season DataFrames into one big DataFrame\n",
    "    #    - ignore_index=True resets row index after concatenation\n",
    "    # ------------------------------------------------------------\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    #  3. Save the combined data to CSV\n",
    "    #    - index=False prevents writing row numbers\n",
    "    # ------------------------------------------------------------\n",
    "    final_df.to_csv(\n",
    "        \"../Data/FBREF_Top7LeaguesEurope_Season(2019-2024)_Uncleaned.csv\",\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    #  4. Print confirmation + shape of final dataset\n",
    "    # ------------------------------------------------------------\n",
    "    print(\"\\nüéØ Saved successfully!\")\n",
    "    print(\"Shape:\", final_df.shape)\n",
    "\n",
    "else:\n",
    "    # ------------------------------------------------------------\n",
    "    #  5. If no data was scraped at all\n",
    "    # ------------------------------------------------------------\n",
    "    print(\"\\n‚ùå No data scraped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78b0272",
   "metadata": {},
   "source": [
    "---\n",
    "### **üö™ 7) Close Browser**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d91476c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "#  Completely closes the browser AND kills the WebDriver session.\n",
    "# -----------------------------------------------------------------\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
